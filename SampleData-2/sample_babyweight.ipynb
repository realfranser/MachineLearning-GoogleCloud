{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a Sampled Dataset\n",
    "\n",
    "**Learning Objectives**\n",
    "\n",
    "1. Setup up the environment\n",
    "1. Sample the natality dataset to create train, eval, test sets\n",
    "1. Preprocess the data in Pandas dataframe\n",
    "\n",
    "\n",
    "## Introduction \n",
    "In this notebook, we'll read data from BigQuery into our notebook to preprocess the data within a Pandas dataframe for a small, repeatable sample.\n",
    "\n",
    "We will set up the environment, sample the natality dataset to create train, eval, test splits, and preprocess the data in a Pandas dataframe.\n",
    "\n",
    "Each learning objective will correspond to a __#TODO__ in this student lab notebook -- try to complete this notebook first and then review the [solution notebook](https://github.com/GoogleCloudPlatform/training-data-analyst/tree/master/courses/machine_learning/deepdive2/end_to_end_ml/solutions/sample_babyweight.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hJ7ByvoXzpVI"
   },
   "source": [
    "## Set up environment variables and load necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo chown -R jupyter:jupyter /home/jupyter/training-data-analyst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google-cloud-bigquery==1.25.0\n",
      "  Downloading google_cloud_bigquery-1.25.0-py2.py3-none-any.whl (169 kB)\n",
      "\u001b[K     |████████████████████████████████| 169 kB 8.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: protobuf>=3.6.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-bigquery==1.25.0) (3.13.0)\n",
      "Requirement already satisfied: google-auth<2.0dev,>=1.9.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-bigquery==1.25.0) (1.23.0)\n",
      "Collecting google-resumable-media<0.6dev,>=0.5.0\n",
      "  Downloading google_resumable_media-0.5.1-py2.py3-none-any.whl (38 kB)\n",
      "Requirement already satisfied: google-cloud-core<2.0dev,>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-bigquery==1.25.0) (1.3.0)\n",
      "Requirement already satisfied: six<2.0.0dev,>=1.13.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-bigquery==1.25.0) (1.15.0)\n",
      "Requirement already satisfied: google-api-core<2.0dev,>=1.15.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-bigquery==1.25.0) (1.22.4)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from protobuf>=3.6.0->google-cloud-bigquery==1.25.0) (50.3.2)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2.0dev,>=1.9.0->google-cloud-bigquery==1.25.0) (4.1.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2.0dev,>=1.9.0->google-cloud-bigquery==1.25.0) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.5\" in /opt/conda/lib/python3.7/site-packages (from google-auth<2.0dev,>=1.9.0->google-cloud-bigquery==1.25.0) (4.6)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core<2.0dev,>=1.15.0->google-cloud-bigquery==1.25.0) (1.52.0)\n",
      "Requirement already satisfied: pytz in /opt/conda/lib/python3.7/site-packages (from google-api-core<2.0dev,>=1.15.0->google-cloud-bigquery==1.25.0) (2020.4)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core<2.0dev,>=1.15.0->google-cloud-bigquery==1.25.0) (2.24.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2.0dev,>=1.9.0->google-cloud-bigquery==1.25.0) (0.4.8)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2.0dev,>=1.15.0->google-cloud-bigquery==1.25.0) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2.0dev,>=1.15.0->google-cloud-bigquery==1.25.0) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2.0dev,>=1.15.0->google-cloud-bigquery==1.25.0) (2020.11.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2.0dev,>=1.15.0->google-cloud-bigquery==1.25.0) (1.25.11)\n",
      "Installing collected packages: google-resumable-media, google-cloud-bigquery\n",
      "\u001b[31mERROR: After October 2020 you may experience errors when installing or updating packages. This is because pip will change the way that it resolves dependency conflicts.\n",
      "\n",
      "We recommend you use --use-feature=2020-resolver to test your packages with the new resolver before it becomes the default.\n",
      "\n",
      "tfx 0.23.0 requires attrs<20,>=19.3.0, but you'll have attrs 20.3.0 which is incompatible.\n",
      "tfx 0.23.0 requires google-resumable-media<0.7.0,>=0.6.0, but you'll have google-resumable-media 0.5.1 which is incompatible.\n",
      "tfx 0.23.0 requires kubernetes<12,>=10.0.1, but you'll have kubernetes 12.0.0 which is incompatible.\n",
      "tfx 0.23.0 requires pyarrow<0.18,>=0.17, but you'll have pyarrow 2.0.0 which is incompatible.\n",
      "google-cloud-storage 1.30.0 requires google-resumable-media<2.0dev,>=0.6.0, but you'll have google-resumable-media 0.5.1 which is incompatible.\u001b[0m\n",
      "Successfully installed google-cloud-bigquery-1.25.0 google-resumable-media-0.5.1\n"
     ]
    }
   ],
   "source": [
    "!pip install --user google-cloud-bigquery==1.25.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: Restart your kernel to use updated packages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kindly ignore the deprecation warnings and incompatibility errors related to google-cloud-storage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hJ7ByvoXzpVI"
   },
   "source": [
    "**Lab Task #1:** Set up environment variables so that we can use them throughout the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your current GCP Project Name is: \n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# TODO 1\n",
    "# TODO -- Your code here.\n",
    "echo \"Your current GCP Project Name is: \"$PROJECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT = \"qwiklabs-gcp-03-5d3dc033c852\"  # Replace with your PROJECT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create ML datasets by sampling using BigQuery\n",
    "\n",
    "We'll begin by sampling the BigQuery data to create smaller datasets. Let's create a BigQuery client that we'll use throughout the lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bq = bigquery.Client(project = PROJECT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to figure out the right way to divide our hash values to get our desired splits. To do that we need to define some values to hash within the module. Feel free to play around with these values to get the perfect combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "modulo_divisor = 100\n",
    "train_percent = 80.0\n",
    "eval_percent = 10.0\n",
    "\n",
    "train_buckets = int(modulo_divisor * train_percent / 100.0)\n",
    "eval_buckets = int(modulo_divisor * eval_percent / 100.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can make a series of queries to check if our bucketing values result in the correct sizes of each of our dataset splits and then adjust accordingly. Therefore, to make our code more compact and reusable, let's define a function to return the head of a dataframe produced from our queries up to a certain number of rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_dataframe_head_from_query(query, count=10):\n",
    "    \"\"\"Displays count rows from dataframe head from query.\n",
    "    \n",
    "    Args:\n",
    "        query: str, query to be run on BigQuery, results stored in dataframe.\n",
    "        count: int, number of results from head of dataframe to display.\n",
    "    Returns:\n",
    "        Dataframe head with count number of results.\n",
    "    \"\"\"\n",
    "    df = bq.query(\n",
    "        query + \" LIMIT {limit}\".format(\n",
    "            limit=count)).to_dataframe()\n",
    "\n",
    "    return df.head(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our first query, we're going to use the original query above to get our label, features, and columns to combine into our hash which we will use to perform our repeatable splitting. There are only a limited number of years, months, days, and states in the dataset. Let's see what the hash values are. We will need to include all of these extra columns to hash on to get a fairly uniform spread of the data. Feel free to try less or more in the hash and see how it changes your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weight_pounds</th>\n",
       "      <th>is_male</th>\n",
       "      <th>mother_age</th>\n",
       "      <th>plurality</th>\n",
       "      <th>gestation_weeks</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>date</th>\n",
       "      <th>state</th>\n",
       "      <th>mother_birth_state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.063611</td>\n",
       "      <td>True</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>2001</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>CO</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.687028</td>\n",
       "      <td>True</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>33</td>\n",
       "      <td>2001</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>IN</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.561856</td>\n",
       "      <td>True</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>2001</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>MN</td>\n",
       "      <td>MN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.561856</td>\n",
       "      <td>True</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>2001</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>MS</td>\n",
       "      <td>MS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.312733</td>\n",
       "      <td>True</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>2001</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>MO</td>\n",
       "      <td>MO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7.627994</td>\n",
       "      <td>False</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>2001</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>NY</td>\n",
       "      <td>PA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.251004</td>\n",
       "      <td>True</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>2001</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>WA</td>\n",
       "      <td>WA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.500126</td>\n",
       "      <td>False</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>2001</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>OK</td>\n",
       "      <td>LA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7.125340</td>\n",
       "      <td>False</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>2001</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>TX</td>\n",
       "      <td>MS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7.749249</td>\n",
       "      <td>True</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>2001</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>TX</td>\n",
       "      <td>Foreign</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   weight_pounds  is_male  mother_age  plurality  gestation_weeks  year  \\\n",
       "0       7.063611     True          32          1               37  2001   \n",
       "1       4.687028     True          30          3               33  2001   \n",
       "2       7.561856     True          20          1               39  2001   \n",
       "3       7.561856     True          31          1               37  2001   \n",
       "4       7.312733     True          32          1               40  2001   \n",
       "5       7.627994    False          30          1               40  2001   \n",
       "6       7.251004     True          33          1               37  2001   \n",
       "7       7.500126    False          23          1               39  2001   \n",
       "8       7.125340    False          33          1               39  2001   \n",
       "9       7.749249     True          31          1               39  2001   \n",
       "\n",
       "   month  date state mother_birth_state  \n",
       "0     12     3    CO                 CA  \n",
       "1      6     5    IN                 IN  \n",
       "2      4     5    MN                 MN  \n",
       "3     10     5    MS                 MS  \n",
       "4     11     3    MO                 MO  \n",
       "5     10     5    NY                 PA  \n",
       "6     11     5    WA                 WA  \n",
       "7      9     2    OK                 LA  \n",
       "8      1     4    TX                 MS  \n",
       "9      1     1    TX            Foreign  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get label, features, and columns to hash and split into buckets\n",
    "hash_cols_fixed_query = \"\"\"\n",
    "SELECT\n",
    "    weight_pounds,\n",
    "    is_male,\n",
    "    mother_age,\n",
    "    plurality,\n",
    "    gestation_weeks,\n",
    "    year,\n",
    "    month,\n",
    "    CASE\n",
    "        WHEN day IS NULL THEN\n",
    "            CASE\n",
    "                WHEN wday IS NULL THEN 0\n",
    "                ELSE wday\n",
    "            END\n",
    "        ELSE day\n",
    "    END AS date,\n",
    "    IFNULL(state, \"Unknown\") AS state,\n",
    "    IFNULL(mother_birth_state, \"Unknown\") AS mother_birth_state\n",
    "FROM\n",
    "    publicdata.samples.natality\n",
    "WHERE\n",
    "    year > 2000\n",
    "    AND weight_pounds > 0\n",
    "    AND mother_age > 0\n",
    "    AND plurality > 0\n",
    "    AND gestation_weeks > 0\n",
    "\"\"\"\n",
    "\n",
    "display_dataframe_head_from_query(hash_cols_fixed_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `COALESCE` would provide the same result as the nested `CASE WHEN`. This is preferable when all we want is the first non-null instance. To be precise the `CASE WHEN` would become `COALESCE(wday, day, 0) AS date`. You can read more about it [here](https://cloud.google.com/bigquery/docs/reference/standard-sql/conditional_expressions)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next query will combine our hash columns and will leave us just with our label, features, and our hash values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weight_pounds</th>\n",
       "      <th>is_male</th>\n",
       "      <th>mother_age</th>\n",
       "      <th>plurality</th>\n",
       "      <th>gestation_weeks</th>\n",
       "      <th>hash_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.063611</td>\n",
       "      <td>True</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>4762325092919148672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.687028</td>\n",
       "      <td>True</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>33</td>\n",
       "      <td>2341060194216507348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.561856</td>\n",
       "      <td>True</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>-8842767231851202242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.561856</td>\n",
       "      <td>True</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>7957807816914159435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.312733</td>\n",
       "      <td>True</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>-5961624242430066305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7.627994</td>\n",
       "      <td>False</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>5493295634082918412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.251004</td>\n",
       "      <td>True</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>-2988893757655690534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.500126</td>\n",
       "      <td>False</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>-6735199252008114417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7.125340</td>\n",
       "      <td>False</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>-3514093303120687641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7.749249</td>\n",
       "      <td>True</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>2175328516857391398</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   weight_pounds  is_male  mother_age  plurality  gestation_weeks  \\\n",
       "0       7.063611     True          32          1               37   \n",
       "1       4.687028     True          30          3               33   \n",
       "2       7.561856     True          20          1               39   \n",
       "3       7.561856     True          31          1               37   \n",
       "4       7.312733     True          32          1               40   \n",
       "5       7.627994    False          30          1               40   \n",
       "6       7.251004     True          33          1               37   \n",
       "7       7.500126    False          23          1               39   \n",
       "8       7.125340    False          33          1               39   \n",
       "9       7.749249     True          31          1               39   \n",
       "\n",
       "           hash_values  \n",
       "0  4762325092919148672  \n",
       "1  2341060194216507348  \n",
       "2 -8842767231851202242  \n",
       "3  7957807816914159435  \n",
       "4 -5961624242430066305  \n",
       "5  5493295634082918412  \n",
       "6 -2988893757655690534  \n",
       "7 -6735199252008114417  \n",
       "8 -3514093303120687641  \n",
       "9  2175328516857391398  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_query = \"\"\"\n",
    "SELECT\n",
    "    weight_pounds,\n",
    "    is_male,\n",
    "    mother_age,\n",
    "    plurality,\n",
    "    gestation_weeks,\n",
    "    FARM_FINGERPRINT(\n",
    "        CONCAT(\n",
    "            CAST(year AS STRING),\n",
    "            CAST(month AS STRING),\n",
    "            CAST(date AS STRING),\n",
    "            CAST(state AS STRING),\n",
    "            CAST(mother_birth_state AS STRING)\n",
    "        )\n",
    "    ) AS hash_values\n",
    "FROM\n",
    "    ({CTE_hash_cols_fixed})\n",
    "\"\"\".format(CTE_hash_cols_fixed=hash_cols_fixed_query)\n",
    "\n",
    "display_dataframe_head_from_query(data_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next query is going to find the counts of each of the unique 657484 `hash_values`. This will be our first step at making actual hash buckets for our split via the `GROUP BY`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hash_values</th>\n",
       "      <th>num_records</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1700820252994836306</td>\n",
       "      <td>741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7948408306271784936</td>\n",
       "      <td>883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1740303207227716653</td>\n",
       "      <td>794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5160546322234461939</td>\n",
       "      <td>2887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-6766011436514751671</td>\n",
       "      <td>178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-3974717950920322290</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-8405995084719745013</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8641800065663952690</td>\n",
       "      <td>875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-2290255568977475467</td>\n",
       "      <td>212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-646460941575642964</td>\n",
       "      <td>463</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           hash_values  num_records\n",
       "0 -1700820252994836306          741\n",
       "1  7948408306271784936          883\n",
       "2 -1740303207227716653          794\n",
       "3  5160546322234461939         2887\n",
       "4 -6766011436514751671          178\n",
       "5 -3974717950920322290           78\n",
       "6 -8405995084719745013            2\n",
       "7  8641800065663952690          875\n",
       "8 -2290255568977475467          212\n",
       "9  -646460941575642964          463"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the counts of each of the unique hash of our splitting column\n",
    "first_bucketing_query = \"\"\"\n",
    "SELECT\n",
    "    hash_values,\n",
    "    COUNT(*) AS num_records\n",
    "FROM\n",
    "    ({CTE_data})\n",
    "GROUP BY\n",
    "    hash_values\n",
    "\"\"\".format(CTE_data=data_query)\n",
    "\n",
    "display_dataframe_head_from_query(first_bucketing_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The query below performs a second layer of bucketing where now for each of these bucket indices we count the number of records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bucket_index</th>\n",
       "      <th>num_records</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>62</td>\n",
       "      <td>426834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46</td>\n",
       "      <td>281627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>76</td>\n",
       "      <td>354090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>87</td>\n",
       "      <td>523881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>277395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>63</td>\n",
       "      <td>355283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>58</td>\n",
       "      <td>209618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>66</td>\n",
       "      <td>402627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>34</td>\n",
       "      <td>379000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>56</td>\n",
       "      <td>226752</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bucket_index  num_records\n",
       "0            62       426834\n",
       "1            46       281627\n",
       "2            76       354090\n",
       "3            87       523881\n",
       "4             0       277395\n",
       "5            63       355283\n",
       "6            58       209618\n",
       "7            66       402627\n",
       "8            34       379000\n",
       "9            56       226752"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the number of records in each of the hash buckets\n",
    "second_bucketing_query = \"\"\"\n",
    "SELECT\n",
    "    ABS(MOD(hash_values, {modulo_divisor})) AS bucket_index,\n",
    "    SUM(num_records) AS num_records\n",
    "FROM\n",
    "    ({CTE_first_bucketing})\n",
    "GROUP BY\n",
    "    ABS(MOD(hash_values, {modulo_divisor}))\n",
    "\"\"\".format(\n",
    "    CTE_first_bucketing=first_bucketing_query, modulo_divisor=modulo_divisor)\n",
    "\n",
    "display_dataframe_head_from_query(second_bucketing_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of records is hard for us to easily understand the split, so we will normalize the count into percentage of the data in each of the hash buckets in the next query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bucket_index</th>\n",
       "      <th>num_records</th>\n",
       "      <th>percent_records</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>70</td>\n",
       "      <td>285539</td>\n",
       "      <td>0.008650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>91</td>\n",
       "      <td>333267</td>\n",
       "      <td>0.010096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>78</td>\n",
       "      <td>326758</td>\n",
       "      <td>0.009898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>277395</td>\n",
       "      <td>0.008403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>398118</td>\n",
       "      <td>0.012060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9</td>\n",
       "      <td>236637</td>\n",
       "      <td>0.007168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>33</td>\n",
       "      <td>410226</td>\n",
       "      <td>0.012427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6</td>\n",
       "      <td>548778</td>\n",
       "      <td>0.016624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>84</td>\n",
       "      <td>341155</td>\n",
       "      <td>0.010334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>38</td>\n",
       "      <td>338150</td>\n",
       "      <td>0.010243</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bucket_index  num_records  percent_records\n",
       "0            70       285539         0.008650\n",
       "1            91       333267         0.010096\n",
       "2            78       326758         0.009898\n",
       "3             0       277395         0.008403\n",
       "4             4       398118         0.012060\n",
       "5             9       236637         0.007168\n",
       "6            33       410226         0.012427\n",
       "7             6       548778         0.016624\n",
       "8            84       341155         0.010334\n",
       "9            38       338150         0.010243"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the overall percentages\n",
    "percentages_query = \"\"\"\n",
    "SELECT\n",
    "    bucket_index,\n",
    "    num_records,\n",
    "    CAST(num_records AS FLOAT64) / (\n",
    "    SELECT\n",
    "        SUM(num_records)\n",
    "    FROM\n",
    "        ({CTE_second_bucketing})) AS percent_records\n",
    "FROM\n",
    "    ({CTE_second_bucketing})\n",
    "\"\"\".format(CTE_second_bucketing=second_bucketing_query)\n",
    "\n",
    "display_dataframe_head_from_query(percentages_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll now select the range of buckets to be used in training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bucket_index</th>\n",
       "      <th>num_records</th>\n",
       "      <th>percent_records</th>\n",
       "      <th>dataset_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>236637</td>\n",
       "      <td>0.007168</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>333513</td>\n",
       "      <td>0.010103</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>432535</td>\n",
       "      <td>0.013103</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>263367</td>\n",
       "      <td>0.007978</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39</td>\n",
       "      <td>224255</td>\n",
       "      <td>0.006793</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>492473</td>\n",
       "      <td>0.014918</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>45</td>\n",
       "      <td>265930</td>\n",
       "      <td>0.008056</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>33</td>\n",
       "      <td>410226</td>\n",
       "      <td>0.012427</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>53</td>\n",
       "      <td>230298</td>\n",
       "      <td>0.006976</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>73</td>\n",
       "      <td>411771</td>\n",
       "      <td>0.012474</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bucket_index  num_records  percent_records dataset_name\n",
       "0             9       236637         0.007168        train\n",
       "1            30       333513         0.010103        train\n",
       "2            20       432535         0.013103        train\n",
       "3            15       263367         0.007978        train\n",
       "4            39       224255         0.006793        train\n",
       "5             2       492473         0.014918        train\n",
       "6            45       265930         0.008056        train\n",
       "7            33       410226         0.012427        train\n",
       "8            53       230298         0.006976        train\n",
       "9            73       411771         0.012474        train"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose hash buckets for training and pull in their statistics\n",
    "train_query = \"\"\"\n",
    "SELECT\n",
    "    *,\n",
    "    \"train\" AS dataset_name\n",
    "FROM\n",
    "    ({CTE_percentages})\n",
    "WHERE\n",
    "    bucket_index >= 0\n",
    "    AND bucket_index < {train_buckets}\n",
    "\"\"\".format(\n",
    "    CTE_percentages=percentages_query,\n",
    "    train_buckets=train_buckets)\n",
    "\n",
    "display_dataframe_head_from_query(train_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll do the same by selecting the range of buckets to be used evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bucket_index</th>\n",
       "      <th>num_records</th>\n",
       "      <th>percent_records</th>\n",
       "      <th>dataset_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>88</td>\n",
       "      <td>423809</td>\n",
       "      <td>0.012838</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85</td>\n",
       "      <td>368045</td>\n",
       "      <td>0.011149</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>87</td>\n",
       "      <td>523881</td>\n",
       "      <td>0.015870</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>89</td>\n",
       "      <td>256482</td>\n",
       "      <td>0.007770</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>82</td>\n",
       "      <td>468179</td>\n",
       "      <td>0.014182</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>84</td>\n",
       "      <td>341155</td>\n",
       "      <td>0.010334</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>80</td>\n",
       "      <td>312489</td>\n",
       "      <td>0.009466</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>83</td>\n",
       "      <td>411258</td>\n",
       "      <td>0.012458</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>81</td>\n",
       "      <td>233538</td>\n",
       "      <td>0.007074</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>86</td>\n",
       "      <td>274489</td>\n",
       "      <td>0.008315</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bucket_index  num_records  percent_records dataset_name\n",
       "0            88       423809         0.012838         eval\n",
       "1            85       368045         0.011149         eval\n",
       "2            87       523881         0.015870         eval\n",
       "3            89       256482         0.007770         eval\n",
       "4            82       468179         0.014182         eval\n",
       "5            84       341155         0.010334         eval\n",
       "6            80       312489         0.009466         eval\n",
       "7            83       411258         0.012458         eval\n",
       "8            81       233538         0.007074         eval\n",
       "9            86       274489         0.008315         eval"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose hash buckets for validation and pull in their statistics\n",
    "eval_query = \"\"\"\n",
    "SELECT\n",
    "    *,\n",
    "    \"eval\" AS dataset_name\n",
    "FROM\n",
    "    ({CTE_percentages})\n",
    "WHERE\n",
    "    bucket_index >= {train_buckets}\n",
    "    AND bucket_index < {cum_eval_buckets}\n",
    "\"\"\".format(\n",
    "    CTE_percentages=percentages_query,\n",
    "    train_buckets=train_buckets,\n",
    "    cum_eval_buckets=train_buckets + eval_buckets)\n",
    "\n",
    "display_dataframe_head_from_query(eval_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we'll select the hash buckets to be used for the test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bucket_index</th>\n",
       "      <th>num_records</th>\n",
       "      <th>percent_records</th>\n",
       "      <th>dataset_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>96</td>\n",
       "      <td>529357</td>\n",
       "      <td>0.016036</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>93</td>\n",
       "      <td>215710</td>\n",
       "      <td>0.006534</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>98</td>\n",
       "      <td>374697</td>\n",
       "      <td>0.011351</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>97</td>\n",
       "      <td>480790</td>\n",
       "      <td>0.014564</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>91</td>\n",
       "      <td>333267</td>\n",
       "      <td>0.010096</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>94</td>\n",
       "      <td>431001</td>\n",
       "      <td>0.013056</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>90</td>\n",
       "      <td>286465</td>\n",
       "      <td>0.008678</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>95</td>\n",
       "      <td>313544</td>\n",
       "      <td>0.009498</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>92</td>\n",
       "      <td>336735</td>\n",
       "      <td>0.010201</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>99</td>\n",
       "      <td>223334</td>\n",
       "      <td>0.006765</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bucket_index  num_records  percent_records dataset_name\n",
       "0            96       529357         0.016036         test\n",
       "1            93       215710         0.006534         test\n",
       "2            98       374697         0.011351         test\n",
       "3            97       480790         0.014564         test\n",
       "4            91       333267         0.010096         test\n",
       "5            94       431001         0.013056         test\n",
       "6            90       286465         0.008678         test\n",
       "7            95       313544         0.009498         test\n",
       "8            92       336735         0.010201         test\n",
       "9            99       223334         0.006765         test"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose hash buckets for testing and pull in their statistics\n",
    "test_query = \"\"\"\n",
    "SELECT\n",
    "    *,\n",
    "    \"test\" AS dataset_name\n",
    "FROM\n",
    "    ({CTE_percentages})\n",
    "WHERE\n",
    "    bucket_index >= {cum_eval_buckets}\n",
    "    AND bucket_index < {modulo_divisor}\n",
    "\"\"\".format(\n",
    "    CTE_percentages=percentages_query,\n",
    "    cum_eval_buckets=train_buckets + eval_buckets,\n",
    "    modulo_divisor=modulo_divisor)\n",
    "\n",
    "display_dataframe_head_from_query(test_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the below query, we'll `UNION ALL` all of the datasets together so that all three sets of hash buckets will be within one table. We added `dataset_id` so that we can sort on it in the query after."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset_id</th>\n",
       "      <th>bucket_index</th>\n",
       "      <th>num_records</th>\n",
       "      <th>percent_records</th>\n",
       "      <th>dataset_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>246041</td>\n",
       "      <td>0.007453</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>196889</td>\n",
       "      <td>0.005964</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>372457</td>\n",
       "      <td>0.011283</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>449280</td>\n",
       "      <td>0.013610</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>250505</td>\n",
       "      <td>0.007588</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>379000</td>\n",
       "      <td>0.011481</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>263367</td>\n",
       "      <td>0.007978</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>71</td>\n",
       "      <td>260774</td>\n",
       "      <td>0.007900</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>277395</td>\n",
       "      <td>0.008403</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>257140</td>\n",
       "      <td>0.007789</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset_id  bucket_index  num_records  percent_records dataset_name\n",
       "0           0            36       246041         0.007453        train\n",
       "1           0             3       196889         0.005964        train\n",
       "2           0            67       372457         0.011283        train\n",
       "3           0             5       449280         0.013610        train\n",
       "4           0            35       250505         0.007588        train\n",
       "5           0            34       379000         0.011481        train\n",
       "6           0            15       263367         0.007978        train\n",
       "7           0            71       260774         0.007900        train\n",
       "8           0             0       277395         0.008403        train\n",
       "9           0            22       257140         0.007789        train"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Union the training, validation, and testing dataset statistics\n",
    "union_query = \"\"\"\n",
    "SELECT\n",
    "    0 AS dataset_id,\n",
    "    *\n",
    "FROM\n",
    "    ({CTE_train})\n",
    "UNION ALL\n",
    "SELECT\n",
    "    1 AS dataset_id,\n",
    "    *\n",
    "FROM\n",
    "    ({CTE_eval})\n",
    "UNION ALL\n",
    "SELECT\n",
    "    2 AS dataset_id,\n",
    "    *\n",
    "FROM\n",
    "    ({CTE_test})\n",
    "\"\"\".format(CTE_train=train_query, CTE_eval=eval_query, CTE_test=test_query)\n",
    "\n",
    "display_dataframe_head_from_query(union_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we'll show the final split between train, eval, and test sets. We can see both the number of records and percent of the total data. It is really close to that we were hoping to get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset_id</th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>num_records</th>\n",
       "      <th>percent_records</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>25873134</td>\n",
       "      <td>0.783765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>eval</td>\n",
       "      <td>3613325</td>\n",
       "      <td>0.109457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>test</td>\n",
       "      <td>3524900</td>\n",
       "      <td>0.106778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset_id dataset_name  num_records  percent_records\n",
       "0           0        train     25873134         0.783765\n",
       "1           1         eval      3613325         0.109457\n",
       "2           2         test      3524900         0.106778"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show final splitting and associated statistics\n",
    "split_query = \"\"\"\n",
    "SELECT\n",
    "    dataset_id,\n",
    "    dataset_name,\n",
    "    SUM(num_records) AS num_records,\n",
    "    SUM(percent_records) AS percent_records\n",
    "FROM\n",
    "    ({CTE_union})\n",
    "GROUP BY\n",
    "    dataset_id,\n",
    "    dataset_name\n",
    "ORDER BY\n",
    "    dataset_id\n",
    "\"\"\".format(CTE_union=union_query)\n",
    "\n",
    "display_dataframe_head_from_query(split_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know that our splitting values produce a good global splitting on our data, here's a way to get a well-distributed portion of the data in such a way that the train, eval, test sets do not overlap and takes a subsample of our global splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_from_query(query, count=10):\n",
    "    \"\"\"Displays count rows from dataframe head from query.\n",
    "    \n",
    "    Args:\n",
    "        query: str, query to be run on BigQuery, results stored in dataframe.\n",
    "        count: int, number of results from head of dataframe to display.\n",
    "    Returns:\n",
    "        Dataframe head with count number of results.\n",
    "    \"\"\"\n",
    "    df = bq.query(\n",
    "        query + \" LIMIT {limit}\".format(\n",
    "            limit=count)).to_dataframe()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the number of records in each of the hash buckets\n",
    "get_train_df = \"\"\"\n",
    "SELECT\n",
    "\tweight_pounds,\n",
    "    is_male,\n",
    "    mother_age,\n",
    "    plurality,\n",
    "    gestation_weeks,    \n",
    "FROM\n",
    "    ({CTE_first_bucketing})\n",
    "WHERE\n",
    "     ABS(MOD(hash_values, {modulo_divisor})) < {train_buckets}\n",
    "\"\"\".format(\n",
    "    CTE_first_bucketing=first_bucketing_query, modulo_divisor=modulo_divisor,train_buckets=train_buckets)\n",
    "\n",
    "# Get the number of records in each of the hash buckets\n",
    "get_eval_df = \"\"\"\n",
    "SELECT\n",
    "\tweight_pounds,\n",
    "    is_male,\n",
    "    mother_age,\n",
    "    plurality,\n",
    "    gestation_weeks,    \n",
    "FROM\n",
    "    ({CTE_first_bucketing})\n",
    "WHERE\n",
    "     ABS(MOD(hash_values, {modulo_divisor})) >= {train_buckets}\n",
    "     AND ABS(MOD(hash_values, {modulo_divisor})) < {cum_eval_buckets}\n",
    "\"\"\".format(\n",
    "    CTE_first_bucketing=first_bucketing_query, modulo_divisor=modulo_divisor, train_buckets=train_buckets,\n",
    "    cum_eval_buckets=train_buckets + eval_buckets)\n",
    "\n",
    "# Get the number of records in each of the hash buckets\n",
    "get_test_df = \"\"\"\n",
    "SELECT\n",
    "\tweight_pounds,\n",
    "    is_male,\n",
    "    mother_age,\n",
    "    plurality,\n",
    "    gestation_weeks,    \n",
    "FROM\n",
    "    ({CTE_first_bucketing})\n",
    "WHERE\n",
    "     ABS(MOD(hash_values, {modulo_divisor})) >= {cum_eval_buckets}\n",
    "     AND ABS(MOD(hash_values, {modulo_divisor})) < {modulo_divisor}\n",
    "\"\"\".format(\n",
    "    CTE_first_bucketing=first_bucketing_query, modulo_divisor=modulo_divisor,cum_eval_buckets=train_buckets + eval_buckets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lab Task #2:** Sample the natality dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 100 examples in the train dataset.\n",
      "There are 100 examples in the validation dataset.\n",
      "There are 100 examples in the test dataset.\n"
     ]
    }
   ],
   "source": [
    "# TODO 2\n",
    "# TODO -- Your code here.\n",
    "# every_n allows us to subsample from each of the hash values\n",
    "train_df = dataframe_from_query(data_query,100)\n",
    "eval_df = dataframe_from_query(data_query,100)\n",
    "test_df = dataframe_from_query(data_query,100)\n",
    "# This helps us get approximately the record counts we want\n",
    "print(\"There are {} examples in the train dataset.\".format(len(train_df)))\n",
    "print(\"There are {} examples in the validation dataset.\".format(len(eval_df)))\n",
    "print(\"There are {} examples in the test dataset.\".format(len(test_df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess data using Pandas\n",
    "\n",
    "We'll perform a few preprocessing steps to the data in our dataset. Let's add extra rows to simulate the lack of ultrasound. That is we'll duplicate some rows and make the `is_male` field be `Unknown`. Also, if there is more than child we'll change the `plurality` to `Multiple(2+)`. While we're at it, we'll also change the plurality column to be a string. We'll perform these operations below. \n",
    "\n",
    "Let's start by examining the training dataset as is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weight_pounds</th>\n",
       "      <th>is_male</th>\n",
       "      <th>mother_age</th>\n",
       "      <th>plurality</th>\n",
       "      <th>gestation_weeks</th>\n",
       "      <th>hash_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.695846</td>\n",
       "      <td>False</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>-8036809554133325397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.687926</td>\n",
       "      <td>True</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>-6132026233917866995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.936641</td>\n",
       "      <td>False</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>8439164539444335271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.198992</td>\n",
       "      <td>True</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>410994157116516864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.061406</td>\n",
       "      <td>False</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>-4947124986429933431</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   weight_pounds  is_male  mother_age  plurality  gestation_weeks  \\\n",
       "0       4.695846    False          31          1               32   \n",
       "1       5.687926     True          30          1               36   \n",
       "2       7.936641    False          24          1               39   \n",
       "3       8.198992     True          29          1               39   \n",
       "4       7.061406    False          40          1               37   \n",
       "\n",
       "           hash_values  \n",
       "0 -8036809554133325397  \n",
       "1 -6132026233917866995  \n",
       "2  8439164539444335271  \n",
       "3   410994157116516864  \n",
       "4 -4947124986429933431  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, notice that there are some very important numeric fields that are missing in some rows (the count in Pandas doesn't count missing data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weight_pounds</th>\n",
       "      <th>mother_age</th>\n",
       "      <th>plurality</th>\n",
       "      <th>gestation_weeks</th>\n",
       "      <th>hash_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1.000000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7.431849</td>\n",
       "      <td>26.710000</td>\n",
       "      <td>1.030000</td>\n",
       "      <td>38.880000</td>\n",
       "      <td>5.249029e+17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.200063</td>\n",
       "      <td>6.141916</td>\n",
       "      <td>0.171447</td>\n",
       "      <td>1.950291</td>\n",
       "      <td>5.345227e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.499635</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>-9.192824e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.686620</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>-3.573048e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.593823</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>7.224660e+17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.190724</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>5.152596e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10.500618</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>9.221737e+18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       weight_pounds  mother_age   plurality  gestation_weeks   hash_values\n",
       "count     100.000000  100.000000  100.000000       100.000000  1.000000e+02\n",
       "mean        7.431849   26.710000    1.030000        38.880000  5.249029e+17\n",
       "std         1.200063    6.141916    0.171447         1.950291  5.345227e+18\n",
       "min         4.499635   16.000000    1.000000        32.000000 -9.192824e+18\n",
       "25%         6.686620   21.000000    1.000000        38.000000 -3.573048e+18\n",
       "50%         7.593823   27.000000    1.000000        39.000000  7.224660e+17\n",
       "75%         8.190724   31.000000    1.000000        40.000000  5.152596e+18\n",
       "max        10.500618   42.000000    2.000000        43.000000  9.221737e+18"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is always crucial to clean raw data before using in machine learning, so we have a preprocessing step. We'll define a `preprocess` function below. Note that the mother's age is an input to our model so users will have to provide the mother's age; otherwise, our service won't work. The features we use for our model were chosen because they are such good predictors and because they are easy enough to collect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hJ7ByvoXzpVI"
   },
   "source": [
    "**Lab Task #3:** Preprocess the data in Pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "   # TODO 3\n",
    "   # TODO -- Your code here.\n",
    "def preprocess (df):    \n",
    "    # Modify plurality field to be a string\n",
    "    twins_etc = dict(zip([1,2,3,4,5],\n",
    "                   [\"Single(1)\",\n",
    "                    \"Twins(2)\",\n",
    "                    \"Triplets(3)\",\n",
    "                    \"Quadruplets(4)\",\n",
    "                    \"Quintuplets(5)\"]))\n",
    "    df[\"plurality\"].replace(twins_etc, inplace=True)\n",
    "\n",
    "    # Clone data and mask certain columns to simulate lack of ultrasound\n",
    "    no_ultrasound = df.copy(deep=True)\n",
    "\n",
    "    # Modify is_male\n",
    "    no_ultrasound[\"is_male\"] = \"Unknown\"\n",
    "    \n",
    "    # Modify plurality\n",
    "    condition = no_ultrasound[\"plurality\"] != \"Single(1)\"\n",
    "    no_ultrasound.loc[condition, \"plurality\"] = \"Multiple(2+)\"\n",
    "\n",
    "    # Concatenate both datasets together and shuffle\n",
    "    return pd.concat(\n",
    "        [df, no_ultrasound]).sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's process the train, eval, test set and see a small sample of the training data after our preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = preprocess(train_df)\n",
    "eval_df = preprocess(eval_df)\n",
    "test_df = preprocess(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weight_pounds</th>\n",
       "      <th>is_male</th>\n",
       "      <th>mother_age</th>\n",
       "      <th>plurality</th>\n",
       "      <th>gestation_weeks</th>\n",
       "      <th>hash_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.688418</td>\n",
       "      <td>True</td>\n",
       "      <td>31</td>\n",
       "      <td>Single(1)</td>\n",
       "      <td>41</td>\n",
       "      <td>-1569657028734518022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.393406</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>30</td>\n",
       "      <td>Single(1)</td>\n",
       "      <td>38</td>\n",
       "      <td>-1052589534453650062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.136771</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>21</td>\n",
       "      <td>Single(1)</td>\n",
       "      <td>37</td>\n",
       "      <td>-7363173917873728029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.188376</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>42</td>\n",
       "      <td>Single(1)</td>\n",
       "      <td>37</td>\n",
       "      <td>7782266297148452291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.625790</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>22</td>\n",
       "      <td>Single(1)</td>\n",
       "      <td>38</td>\n",
       "      <td>7579041105174423352</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   weight_pounds  is_male  mother_age  plurality  gestation_weeks  \\\n",
       "0       8.688418     True          31  Single(1)               41   \n",
       "1       6.393406  Unknown          30  Single(1)               38   \n",
       "2       5.136771  Unknown          21  Single(1)               37   \n",
       "3       6.188376  Unknown          42  Single(1)               37   \n",
       "4       7.625790  Unknown          22  Single(1)               38   \n",
       "\n",
       "           hash_values  \n",
       "0 -1569657028734518022  \n",
       "1 -1052589534453650062  \n",
       "2 -7363173917873728029  \n",
       "3  7782266297148452291  \n",
       "4  7579041105174423352  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weight_pounds</th>\n",
       "      <th>is_male</th>\n",
       "      <th>mother_age</th>\n",
       "      <th>plurality</th>\n",
       "      <th>gestation_weeks</th>\n",
       "      <th>hash_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>8.198992</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>29</td>\n",
       "      <td>Single(1)</td>\n",
       "      <td>39</td>\n",
       "      <td>410994157116516864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>7.125340</td>\n",
       "      <td>False</td>\n",
       "      <td>25</td>\n",
       "      <td>Single(1)</td>\n",
       "      <td>40</td>\n",
       "      <td>3190725018108452514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>7.625790</td>\n",
       "      <td>True</td>\n",
       "      <td>26</td>\n",
       "      <td>Single(1)</td>\n",
       "      <td>42</td>\n",
       "      <td>5655500751972499290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>6.492614</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>28</td>\n",
       "      <td>Single(1)</td>\n",
       "      <td>41</td>\n",
       "      <td>8297008456970080747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>8.785421</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>24</td>\n",
       "      <td>Single(1)</td>\n",
       "      <td>41</td>\n",
       "      <td>5617905498255901254</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     weight_pounds  is_male  mother_age  plurality  gestation_weeks  \\\n",
       "195       8.198992  Unknown          29  Single(1)               39   \n",
       "196       7.125340    False          25  Single(1)               40   \n",
       "197       7.625790     True          26  Single(1)               42   \n",
       "198       6.492614  Unknown          28  Single(1)               41   \n",
       "199       8.785421  Unknown          24  Single(1)               41   \n",
       "\n",
       "             hash_values  \n",
       "195   410994157116516864  \n",
       "196  3190725018108452514  \n",
       "197  5655500751972499290  \n",
       "198  8297008456970080747  \n",
       "199  5617905498255901254  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look again at a summary of the dataset. Note that we only see numeric columns, so `plurality` does not show up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weight_pounds</th>\n",
       "      <th>mother_age</th>\n",
       "      <th>gestation_weeks</th>\n",
       "      <th>hash_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>2.000000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7.431849</td>\n",
       "      <td>26.710000</td>\n",
       "      <td>38.880000</td>\n",
       "      <td>5.249029e+17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.197044</td>\n",
       "      <td>6.126465</td>\n",
       "      <td>1.945385</td>\n",
       "      <td>5.331780e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.499635</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>-9.192824e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.686620</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>-3.573048e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.593823</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>7.224660e+17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.190724</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>5.152596e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10.500618</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>9.221737e+18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       weight_pounds  mother_age  gestation_weeks   hash_values\n",
       "count     200.000000  200.000000       200.000000  2.000000e+02\n",
       "mean        7.431849   26.710000        38.880000  5.249029e+17\n",
       "std         1.197044    6.126465         1.945385  5.331780e+18\n",
       "min         4.499635   16.000000        32.000000 -9.192824e+18\n",
       "25%         6.686620   21.000000        38.000000 -3.573048e+18\n",
       "50%         7.593823   27.000000        39.000000  7.224660e+17\n",
       "75%         8.190724   31.000000        40.000000  5.152596e+18\n",
       "max        10.500618   42.000000        43.000000  9.221737e+18"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write to .csv files \n",
    "\n",
    "In the final versions, we want to read from files, not Pandas dataframes. So, we write the Pandas dataframes out as csv files. Using csv files gives us the advantage of shuffling during read. This is important for distributed training because some workers might be slower than others, and shuffling the data helps prevent the same data from being assigned to the slow workers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define columns\n",
    "columns = [\"weight_pounds\",\n",
    "           \"is_male\",\n",
    "           \"mother_age\",\n",
    "           \"plurality\",\n",
    "           \"gestation_weeks\"]\n",
    "\n",
    "# Write out CSV files\n",
    "train_df.to_csv(\n",
    "    path_or_buf=\"train.csv\", columns=columns, header=False, index=False)\n",
    "eval_df.to_csv(\n",
    "    path_or_buf=\"eval.csv\", columns=columns, header=False, index=False)\n",
    "test_df.to_csv(\n",
    "    path_or_buf=\"test.csv\", columns=columns, header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  200 eval.csv\n",
      "  200 test.csv\n",
      "  200 train.csv\n",
      "  600 total\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "wc -l *.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> eval.csv <==\n",
      "7.5618555866,False,20,Single(1),43\n",
      "4.7509617461,False,36,Single(1),39\n",
      "6.75055446244,True,21,Single(1),38\n",
      "7.5618555866,Unknown,20,Single(1),43\n",
      "7.91239058318,Unknown,30,Single(1),39\n",
      "5.4454178714,Unknown,30,Single(1),35\n",
      "7.06140625186,Unknown,40,Single(1),37\n",
      "6.87401332916,True,29,Single(1),38\n",
      "8.377565956,Unknown,28,Single(1),42\n",
      "7.5618555866,Unknown,20,Single(1),40\n",
      "\n",
      "==> test.csv <==\n",
      "7.12534030784,True,18,Single(1),42\n",
      "7.0988848364,Unknown,28,Single(1),40\n",
      "9.56365292556,Unknown,30,Single(1),40\n",
      "9.06320359082,Unknown,29,Single(1),41\n",
      "6.1883756943399995,True,17,Single(1),36\n",
      "4.7509617461,Unknown,36,Single(1),39\n",
      "6.41324720158,Unknown,29,Single(1),38\n",
      "6.87621795178,Unknown,19,Single(1),38\n",
      "5.1367707046,True,21,Single(1),37\n",
      "9.16902547658,Unknown,19,Single(1),40\n",
      "\n",
      "==> train.csv <==\n",
      "8.68841774542,True,31,Single(1),41\n",
      "6.393405598,Unknown,30,Single(1),38\n",
      "5.1367707046,Unknown,21,Single(1),37\n",
      "6.1883756943399995,Unknown,42,Single(1),37\n",
      "7.62578964258,Unknown,22,Single(1),38\n",
      "8.344496616699999,False,22,Single(1),39\n",
      "7.81318256528,Unknown,17,Single(1),37\n",
      "7.936641432,True,36,Single(1),38\n",
      "8.93754010148,Unknown,31,Single(1),40\n",
      "8.3665428429,True,25,Single(1),40\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "head *.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> eval.csv <==\n",
      "6.393405598,Unknown,30,Single(1),38\n",
      "6.944561253,Unknown,32,Single(1),37\n",
      "6.4992274837599995,True,31,Twins(2),37\n",
      "7.5618555866,True,20,Single(1),40\n",
      "7.25100379718,Unknown,28,Single(1),39\n",
      "5.3241636273,True,38,Twins(2),34\n",
      "6.0406659788,Unknown,33,Single(1),37\n",
      "7.12534030784,True,18,Single(1),42\n",
      "6.4926136159,Unknown,28,Single(1),41\n",
      "7.12534030784,Unknown,25,Single(1),39\n",
      "\n",
      "==> test.csv <==\n",
      "5.8753192823,True,21,Single(1),36\n",
      "7.13856804356,Unknown,22,Single(1),38\n",
      "7.12534030784,Unknown,18,Single(1),42\n",
      "5.4454178714,Unknown,30,Single(1),35\n",
      "7.06140625186,Unknown,40,Single(1),37\n",
      "7.31273323054,Unknown,23,Single(1),39\n",
      "5.8135898489399995,False,37,Single(1),37\n",
      "9.93843877096,Unknown,28,Single(1),41\n",
      "7.936641432,False,19,Single(1),40\n",
      "7.0988848364,False,28,Single(1),40\n",
      "\n",
      "==> train.csv <==\n",
      "8.375361333379999,True,30,Single(1),40\n",
      "7.3744626639,Unknown,26,Single(1),39\n",
      "4.7509617461,False,36,Single(1),39\n",
      "6.75055446244,Unknown,29,Single(1),38\n",
      "7.91239058318,False,30,Single(1),39\n",
      "8.19899152378,Unknown,29,Single(1),39\n",
      "7.12534030784,False,25,Single(1),40\n",
      "7.62578964258,True,26,Single(1),42\n",
      "6.4926136159,Unknown,28,Single(1),41\n",
      "8.7854211407,Unknown,24,Single(1),41\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "tail *.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Summary: \n",
    "In this lab, we set up the environment, sampled the natality dataset to create train, eval, test splits, and preprocessed the data in a Pandas dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright 2020 Google Inc. Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-2-3-gpu.2-3.m59",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-2-3-gpu.2-3:m59"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
